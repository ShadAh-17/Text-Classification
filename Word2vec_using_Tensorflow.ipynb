{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jODMqRUOvKL"
   },
   "source": [
    "# Word2Vec\n",
    "I have implemented word2vec (Word Embedding) with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peBWUHkAOvKO"
   },
   "source": [
    "# Collection of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JonjuPbDOvKQ"
   },
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iioarh4DOvKZ"
   },
   "source": [
    "# Remove stop words\n",
    "In order for efficiency of creating word vector, remove commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lExSHZfbOvKb"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXSFtYBDOvKi"
   },
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i40hDDimOvKr"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "59TUuvguOvLC",
    "outputId": "612e070e-2600-467f-ab7b-55e345efe976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSSn9J9lOvLY"
   },
   "source": [
    "# Data generation\n",
    "### Generate label for each word using skip gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go7AB69uOvLb"
   },
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "-4MWw2E2OvLm",
    "outputId": "517a4e1c-53e9-4ef5-931d-fef5708d128e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "KxOEgOh3OvLw",
    "outputId": "90407402-f3fe-4e02-f3c8-7376279725f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input   label\n",
       "0    king  strong\n",
       "1    king     man\n",
       "2  strong    king\n",
       "3  strong     man\n",
       "4     man    king\n",
       "5     man  strong\n",
       "6   queen    wise\n",
       "7   queen   woman\n",
       "8    wise   queen\n",
       "9    wise   woman"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SUf-ztKSOvL4",
    "outputId": "99161d29-a972-4bec-ab34-da9bf48018ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "o2yxXGfJOvMC",
    "outputId": "3d8dee6d-4cc5-40a5-f938-8f57a0187365"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy': 6,\n",
       " 'girl': 8,\n",
       " 'king': 0,\n",
       " 'man': 1,\n",
       " 'pretty': 4,\n",
       " 'prince': 7,\n",
       " 'princess': 3,\n",
       " 'queen': 5,\n",
       " 'strong': 11,\n",
       " 'wise': 9,\n",
       " 'woman': 2,\n",
       " 'young': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF09-eneOvMK"
   },
   "source": [
    "# Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffSwN1_GOvMM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "Po_MzEs8OvMT",
    "outputId": "e4ca91bc-40b5-4bf6-9b1d-f56d77af3097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBUSLB7kOvMZ"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "ADVN6ZL0OvMb",
    "outputId": "4ff77ed6-f828-45e6-89eb-559fd5e6009a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  4.063403\n",
      "iteration 3000 loss is :  1.8249669\n",
      "iteration 6000 loss is :  1.7692031\n",
      "iteration 9000 loss is :  1.7430705\n",
      "iteration 12000 loss is :  1.7258947\n",
      "iteration 15000 loss is :  1.7151566\n",
      "iteration 18000 loss is :  1.707733\n",
      "iteration 21000 loss is :  1.702002\n",
      "iteration 24000 loss is :  1.69729\n",
      "iteration 27000 loss is :  1.6932849\n",
      "iteration 30000 loss is :  1.6898079\n",
      "iteration 33000 loss is :  1.6867429\n",
      "iteration 36000 loss is :  1.6840081\n",
      "iteration 39000 loss is :  1.6815438\n",
      "iteration 42000 loss is :  1.6793052\n",
      "iteration 45000 loss is :  1.6772577\n",
      "iteration 48000 loss is :  1.6753739\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 50000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Tv5RdZa8OvMj",
    "outputId": "94d62fb2-3bc4-4a03-fd0a-d51ac1a4b14d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10216427  1.5687273 ]\n",
      " [ 0.9436079   7.9123974 ]\n",
      " [ 0.30342937 -0.19369316]\n",
      " [ 5.9726443   2.7930665 ]\n",
      " [ 6.956134   -1.8233651 ]\n",
      " [ 0.81515706 -0.19462788]\n",
      " [-0.03243577  1.458254  ]\n",
      " [ 0.85395765  8.891007  ]\n",
      " [ 1.4783586   0.18217778]\n",
      " [ 7.9195156   0.43559396]\n",
      " [ 0.01054966  0.19404101]\n",
      " [-2.737379    3.6806288 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zf0H_7_TOvMr"
   },
   "source": [
    "# Word Vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "n47GuQwIOvMs",
    "outputId": "79d16c3b-b6cc-41e3-8178-f378ad29a6c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>0.102164</td>\n",
       "      <td>1.568727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man</td>\n",
       "      <td>0.943608</td>\n",
       "      <td>7.912397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.303429</td>\n",
       "      <td>-0.193693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>princess</td>\n",
       "      <td>5.972644</td>\n",
       "      <td>2.793067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty</td>\n",
       "      <td>6.956134</td>\n",
       "      <td>-1.823365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>queen</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>-0.194628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boy</td>\n",
       "      <td>-0.032436</td>\n",
       "      <td>1.458254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prince</td>\n",
       "      <td>0.853958</td>\n",
       "      <td>8.891007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>girl</td>\n",
       "      <td>1.478359</td>\n",
       "      <td>0.182178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>7.919516</td>\n",
       "      <td>0.435594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.194041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>strong</td>\n",
       "      <td>-2.737379</td>\n",
       "      <td>3.680629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0       king  0.102164  1.568727\n",
       "1        man  0.943608  7.912397\n",
       "2      woman  0.303429 -0.193693\n",
       "3   princess  5.972644  2.793067\n",
       "4     pretty  6.956134 -1.823365\n",
       "5      queen  0.815157 -0.194628\n",
       "6        boy -0.032436  1.458254\n",
       "7     prince  0.853958  8.891007\n",
       "8       girl  1.478359  0.182178\n",
       "9       wise  7.919516  0.435594\n",
       "10     young  0.010550  0.194041\n",
       "11    strong -2.737379  3.680629"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJfBFoUbOvMy"
   },
   "source": [
    "# Word Vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kV-jixOCOvMz",
    "outputId": "b3f3a060-edd8-428b-8680-36bd52d38be2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Word2vec using Tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
